{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrB5y-iGsErs"
      },
      "source": [
        "# Übung 1\n",
        "## Das Perzeptron\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ITI-THM/EiDL/blob/master/docs/1-uebung/Perceptron.ipynb)\n",
        "\n",
        "In dieser Übung werden Sie ein einfaches **Perzeptron** implementieren - den grundlegenden Baustein neuronaler Netze. Wie in der Vorlesung besprochen, ist das Perzeptron ein mathematisches Modell eines Neurons und dient zur binären Klassifikation.\n",
        "\n",
        "Die Übung besteht aus zwei Teilen:\n",
        "1. Implementierung eines Perzeptrons von Grund auf mit NumPy\n",
        "2. Implementierung eines Perzeptrons mit PyTorch\n",
        "\n",
        "Ziel ist es, das Perzeptron auf einem einfachen Datensatz zu trainieren und die Entscheidungsgrenze zu visualisieren."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCeKYon7sErv"
      },
      "source": [
        "## Teil 1: Perzeptron von Grund auf implementieren\n",
        "\n",
        "Zunächst implementieren wir ein Perzeptron ohne spezielle Deep-Learning-Bibliotheken, nur mit NumPy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DDMsVaoMsErw"
      },
      "outputs": [],
      "source": [
        "# Benötigte Bibliotheken importieren\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Aktuelle nur um \"schönere\" PLots zu erhalten\n",
        "import seaborn as sns\n",
        "sns.set_theme()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW_Yv-MmsErx"
      },
      "source": [
        "### 1.1 Daten erstellen und Visualisieren\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Erstellen Sie eine Funktion zum visualisieren der Daten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_data(X, y):\n",
        "    #TODO: Visualisiere die Daten mit matplotlib\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Erstellen Sie Daten für die Logischen Operationen AND und OR."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "E1DJLSGosEry",
        "outputId": "c279f920-e536-42ae-af50-4c0bb6319882"
      },
      "outputs": [],
      "source": [
        "# Eingabedaten (Features) für AND- und OR-Operation\n",
        "# X = ?\n",
        "# TODO: Definiere die Eingabedaten für die AND- und OR-Operation\n",
        "\n",
        "# Ausgabedaten (Labels) für AND-Operation\n",
        "# y_and = ?\n",
        "# TODO: Definiere die Ausgabedaten für die AND-Operation\n",
        "\n",
        "# Ausgabedaten (Labels) für OR-Operation\n",
        "# y_or = ?\n",
        "# TODO: Definiere die Ausgabedaten für die OR-Operation\n",
        "\n",
        "# Wähle eine der Operationen für diese Übung\n",
        "y = y_and  # Ändere zu y_or, um die OR-Operation zu trainieren\n",
        "\n",
        "# Daten visualisieren\n",
        "visualize_data(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-70UczIsEry"
      },
      "source": [
        "### 1.2 Aktivierungsfunktion definieren\n",
        "\n",
        "Das Perzeptron verwendet eine Aktivierungsfunktion, um die Ausgabe zu berechnen. Wir implementieren die Sigmoid-Funktion und ihre Ableitung (für den Lernalgorithmus).\n",
        "\n",
        "Sigmoid:\n",
        "$$ f(x)=\\frac{1}{1+e^{-x}} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "kgLOTMnksEry",
        "outputId": "e532582a-6c98-44e3-f95f-59279b952d90"
      },
      "outputs": [],
      "source": [
        "def step_function(x):\n",
        "    # TODO: Implementiere die Schwellenwertfunktion\n",
        "    pass\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"Sigmoid-Aktivierungsfunktion\"\"\"\n",
        "    # TODO: Implementiere die Sigmoid-Funktion\n",
        "    pass\n",
        "\n",
        "def ReLU(x):\n",
        "    # TODO: Implementiere die ReLU-Aktivierungsfunktion\n",
        "    pass\n",
        "\n",
        "# Veranschaulichung der Aktivierungsfunktionen\n",
        "x = np.linspace(-10, 10, 100)\n",
        "plt.figure(figsize=(8, 4))\n",
        "# TODO: Plote die Aktivierungsfunktionen\n",
        "\n",
        "plt.grid(True)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('f(x)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8o9ak4OsErz"
      },
      "source": [
        "### 1.3 Perzeptron-Klasse implementieren\n",
        "\n",
        "Jetzt implementieren wir die Perzeptron-Klasse von Grund auf."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h7bAek_RsErz"
      },
      "outputs": [],
      "source": [
        "class Perzeptron:\n",
        "    def __init__(self, input_size, activation_function):\n",
        "        \"\"\"\n",
        "        Initialisiert ein Perzeptron mit zufälligen Gewichten und Bias.\n",
        "\n",
        "\n",
        "        Args:\n",
        "            input_size: Anzahl der Eingabefeatures\n",
        "        \"\"\"\n",
        "        # TODO: Zufällige Initialisierung von Gewichten und Bias\n",
        "        \n",
        "        pass\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Berechnet die Ausgabe des Perzeptrons für eine Eingabe X.\n",
        "\n",
        "        Args:\n",
        "            X: Eingabedaten, Shape (n_samples, n_features)\n",
        "\n",
        "        Returns:\n",
        "            Ausgabe des Perzeptrons, Shape (n_samples, 1)\n",
        "        \"\"\"\n",
        "        # TODO: Implementiere den Forward-Pass\n",
        "        pass\n",
        "\n",
        "    def train(self, X, y, learning_rate=0.1, epochs=1000):\n",
        "        \"\"\"\n",
        "        Trainiert das Perzeptron mit Hilfe des Gradientenabstiegs.\n",
        "\n",
        "        Args:\n",
        "            X: Eingabedaten, Shape (n_samples, n_features)\n",
        "            y: Zieldaten, Shape (n_samples, 1)\n",
        "            learning_rate: Lernrate\n",
        "            epochs: Anzahl der Trainingsepochen\n",
        "\n",
        "        Returns:\n",
        "            Liste mit Verlustwerten für jede Epoche\n",
        "        \"\"\"\n",
        "        loss_history = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            for xi, yi in zip(X,y):\n",
        "                # TODO: Berechnung der Ausgabe\n",
        "                \n",
        "                # TODO: Berechnung des Verlusts\n",
        "                loss = 0\n",
        "            \n",
        "                # TODO: Update der Gewichte und des Bias\n",
        "                pass\n",
        "\n",
        "            # Alle 100 Epochen Status ausgeben\n",
        "            if epoch % 100 == 0:\n",
        "                print(f'Epoche {epoch}: Verlust = {loss:.4f}')\n",
        "\n",
        "        return loss_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJLlaB96sEr0"
      },
      "source": [
        "### 1.4 Perzeptron trainieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Erstelle eine Funktion zur Visualisierung des Trainingsprozesses\n",
        "def visualize_training(loss_history):\n",
        "    # TODO: Visualisiere den Trainingsprozess\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "cvjS5zefsEr0",
        "outputId": "fe6b39ef-1b43-49e2-add2-b4a23f066c59"
      },
      "outputs": [],
      "source": [
        "# Erstelle und trainiere ein Perzeptron\n",
        "# Was is die input_size?\n",
        "# input_size = ?\n",
        "\n",
        "model = Perzeptron(input_size)\n",
        "loss_history = model.train(X, y, learning_rate=0.1, epochs=1000)\n",
        "\n",
        "# Verlauf des Verlustes visualisieren\n",
        "visualize_training(loss_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etTtalT_sEr0"
      },
      "source": [
        "### 1.5 Ergebnisse auswerten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OggYzBesEr0",
        "outputId": "98c6ee07-a139-485d-f87d-185e70a4ffaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eingaben und Vorhersagen:\n",
            "Eingabe: [0 0], Erwartete Ausgabe: 0.0, Vorhersage: 0.0074\n",
            "Eingabe: [0 1], Erwartete Ausgabe: 0.0, Vorhersage: 0.1438\n",
            "Eingabe: [1 0], Erwartete Ausgabe: 0.0, Vorhersage: 0.1456\n",
            "Eingabe: [1 1], Erwartete Ausgabe: 1.0, Vorhersage: 0.7937\n"
          ]
        }
      ],
      "source": [
        "# Vorhersagen mit dem trainierten Perzeptron\n",
        "predictions = model.forward(X)\n",
        "print(\"Eingaben und Vorhersagen:\")\n",
        "for i in range(len(X)):\n",
        "    print(f\"Eingabe: {X[i]}, Erwartete Ausgabe: {y[i][0]:.1f}, Vorhersage: {predictions[i][0]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8rR1oOMsEr1"
      },
      "source": [
        "### 1.6 Entscheidungsgrenze visualisieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "TpeT9yhcsEr1",
        "outputId": "7835a7aa-ea6c-405f-ebda-10ffbe0f853e"
      },
      "outputs": [],
      "source": [
        "# Erstelle ein Raster von Punkten\n",
        "x1 = np.linspace(-0.1, 1.1, 100)\n",
        "x2 = np.linspace(-0.1, 1.1, 100)\n",
        "x1_grid, x2_grid = np.meshgrid(x1, x2)\n",
        "x_grid = np.c_[x1_grid.flatten(), x2_grid.flatten()]\n",
        "\n",
        "# Vorhersagen für das Raster\n",
        "y_grid = model.forward(x_grid).reshape(100, 100)\n",
        "\n",
        "# Visualisierung der Entscheidungsgrenze\n",
        "plt.figure(figsize=(8, 6))\n",
        "contour = plt.contourf(x1_grid, x2_grid, y_grid, levels=20, cmap='coolwarm', alpha=0.6)\n",
        "plt.colorbar(contour, label='Vorhersage')\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y.flatten(), s=100, edgecolors='k', cmap='coolwarm', label='Trainingsdaten')\n",
        "plt.grid(True)\n",
        "plt.xlim(-0.1, 1.1)\n",
        "plt.ylim(-0.1, 1.1)\n",
        "plt.xlabel('Eingabe 1')\n",
        "plt.ylabel('Eingabe 2')\n",
        "plt.title('Entscheidungsgrenze des trainierten Perzeptrons')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V1GRwDesEr1"
      },
      "source": [
        "## Teil 2: Perzeptron mit PyTorch implementieren\n",
        "\n",
        "Nachdem wir ein Perzeptron von Grund auf implementiert haben, verwenden wir nun PyTorch - eine moderne Deep-Learning-Bibliothek, die automatisches Differenzieren unterstützt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "owv8GcJdsEr2"
      },
      "outputs": [],
      "source": [
        "# PyTorch importieren\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWQ-1wtmsEr2"
      },
      "source": [
        "### 2.1 Daten in PyTorch-Tensoren konvertieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQcShqwXsEr2",
        "outputId": "2e8ffb35-e6dd-4704-ea14-e2b94415b0b1"
      },
      "outputs": [],
      "source": [
        "# NumPy-Arrays zu PyTorch-Tensoren konvertieren\n",
        "# TODO: Konvertiere X und y in PyTorch-Tensoren\n",
        "X_tensor = None\n",
        "y_tensor = None\n",
        "\n",
        "print(\"PyTorch-Tensor für X:\")\n",
        "print(X_tensor)\n",
        "print(\"\\nPyTorch-Tensor für y:\")\n",
        "print(y_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdWgdQwesEr2"
      },
      "source": [
        "### 2.2 Perzeptron-Modell in PyTorch definieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmOaPohtsEr2",
        "outputId": "f0be4216-78cc-496a-b292-0d8e870ec1e1"
      },
      "outputs": [],
      "source": [
        "class PyTorchPerzeptron(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        \"\"\"\n",
        "        Initialisiert ein Perzeptron mit PyTorch.\n",
        "\n",
        "        Args:\n",
        "            input_size: Anzahl der Eingabefeatures\n",
        "        \"\"\"\n",
        "        super(PyTorchPerzeptron, self).__init__()\n",
        "        # Doku zu nn https://pytorch.org/docs/stable/nn.html\n",
        "\n",
        "        # TODO: Definieren der Architektur mit input_size Eingaben und 1 Ausgabe\n",
        "        # Hint: Es handelt sich hier um eine einfache lineare Schicht wx+b\n",
        "\n",
        "        # TODO: Definiere die Aktivierungsfunktion (zunächst Sigmoid)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward-Pass durch das Perzeptron.\n",
        "\n",
        "        Args:\n",
        "            x: Eingabetensor\n",
        "\n",
        "        Returns:\n",
        "            Ausgabe des Perzeptrons\n",
        "        \"\"\"\n",
        "        # TODO: Implementiere den Forward-Pass\n",
        "        pass\n",
        "\n",
        "# Modell initialisieren\n",
        "# input_size = ?\n",
        "model_pytorch = PyTorchPerzeptron(input_size)\n",
        "\n",
        "# Modellstruktur ausgeben\n",
        "print(\"Modellarchitektur:\")\n",
        "print(model_pytorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJGKdLdVsEr3"
      },
      "source": [
        "### 2.3 Modell mit PyTorch trainieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "iE9KqmOFsEr3",
        "outputId": "b68a7b5e-47d5-4a25-8395-0e414a272e5d"
      },
      "outputs": [],
      "source": [
        "# Verlustfunktion definieren (Binary Cross Entropy für binäre Klassifikation)\n",
        "loss_function = nn.BCELoss()\n",
        "\n",
        "# Optimizer definieren (Stochastic Gradient Descent)\n",
        "optimizer = optim.SGD(model_pytorch.parameters(), lr=0.1)\n",
        "\n",
        "# Anzahl der Trainingsepochen\n",
        "epochs = 1000\n",
        "\n",
        "# Trainingsschleife\n",
        "pytorch_loss_history = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Forward-Pass: Vorhersage des Modells\n",
        "    y_pred = model_pytorch(X_tensor)\n",
        "\n",
        "    # Berechnung des Verlusts\n",
        "    loss = loss_function(y_pred, y_tensor)\n",
        "    pytorch_loss_history.append(loss.item())\n",
        "\n",
        "    # Zurücksetzen der Gradienten\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward-Pass: Berechnung der Gradienten\n",
        "    loss.backward()\n",
        "\n",
        "    # Aktualisierung der Gewichte\n",
        "    optimizer.step()\n",
        "\n",
        "    # Alle 100 Epochen Status ausgeben\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoche {epoch}: Verlust = {loss.item():.4f}')\n",
        "\n",
        "# Verlauf des Verlustes visualisieren\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(pytorch_loss_history)\n",
        "plt.grid(True)\n",
        "plt.xlabel('Epoche')\n",
        "plt.ylabel('Verlust')\n",
        "plt.title('Verlauf des Verlustes während des Trainings (PyTorch)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqEqxpncsEr3"
      },
      "source": [
        "### 2.4 Ergebnisse auswerten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM5X5nWqsEr3",
        "outputId": "422cf44d-1bdc-4ce0-f9e7-f3078830c2db"
      },
      "outputs": [],
      "source": [
        "# Vorhersagen mit dem trainierten PyTorch-Modell\n",
        "with torch.no_grad():\n",
        "    predictions_pytorch = model_pytorch(X_tensor)\n",
        "    print(\"Eingaben und Vorhersagen (PyTorch):\")\n",
        "    for i in range(len(X)):\n",
        "        print(f\"Eingabe: {X[i]}, Erwartete Ausgabe: {y[i][0]:.1f}, Vorhersage: {predictions_pytorch[i].item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkO74G4TsEr3"
      },
      "source": [
        "### 2.5 Entscheidungsgrenze visualisieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "7MQoi4MzsEr3",
        "outputId": "92334970-0fd0-4455-b560-a7772b42f9b1"
      },
      "outputs": [],
      "source": [
        "# Erstelle ein Raster von Punkten\n",
        "x1 = np.linspace(0, 1, 100)\n",
        "x2 = np.linspace(0, 1, 100)\n",
        "x1_grid, x2_grid = np.meshgrid(x1, x2)\n",
        "x_grid = np.c_[x1_grid.flatten(), x2_grid.flatten()]\n",
        "x_grid_tensor = torch.FloatTensor(x_grid)\n",
        "\n",
        "# Vorhersagen für das Raster mit PyTorch\n",
        "with torch.no_grad():\n",
        "    y_grid_pytorch = model_pytorch(x_grid_tensor).numpy().reshape(100, 100)\n",
        "\n",
        "# Visualisierung der Entscheidungsgrenze\n",
        "plt.figure(figsize=(8, 6))\n",
        "contour = plt.contourf(x1_grid, x2_grid, y_grid_pytorch, levels=20, cmap='coolwarm', alpha=0.6)\n",
        "plt.colorbar(contour, label='Vorhersage')\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y.flatten(), s=100, edgecolors='k', cmap='coolwarm', label='Trainingsdaten')\n",
        "plt.grid(True)\n",
        "plt.xlabel('Eingabe 1')\n",
        "plt.ylabel('Eingabe 2')\n",
        "plt.title('Entscheidungsgrenze des trainierten Perzeptrons (PyTorch)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEriT0KOsEr3"
      },
      "source": [
        "### 2.6 Gewichte des Perzeptrons untersuchen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "dK5BSiKGsEr4",
        "outputId": "11d7a271-e65a-4467-99c0-e175aa4812f6"
      },
      "outputs": [],
      "source": [
        "# Gewichte und Bias des PyTorch-Modells extrahieren\n",
        "weights_pytorch = model_pytorch.linear.weight.data.numpy()\n",
        "bias_pytorch = model_pytorch.linear.bias.data.numpy()\n",
        "\n",
        "print(f\"Gelernte Gewichte (PyTorch): {weights_pytorch}\")\n",
        "print(f\"Gelernter Bias (PyTorch): {bias_pytorch}\")\n",
        "\n",
        "# Berechnung der Entscheidungsgrenze in der Form: w1*x1 + w2*x2 + b = 0\n",
        "# Die Gerade ist gegeben durch: x2 = (-w1*x1 - b) / w2\n",
        "def decision_boundary_pytorch(x):\n",
        "    return (-weights_pytorch[0, 0] * x - bias_pytorch[0]) / weights_pytorch[0, 1]\n",
        "\n",
        "# Visualisierung der Entscheidungsgrenze als Linie\n",
        "x_values = np.linspace(-0.1, 1.1, 100)\n",
        "y_values_pytorch = decision_boundary_pytorch(x_values)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y.flatten(), s=100, edgecolors='k', cmap='coolwarm')\n",
        "plt.plot(x_values, y_values_pytorch, 'g--', linewidth=2, label='Entscheidungsgrenze (PyTorch)')\n",
        "plt.grid(True)\n",
        "plt.xlabel('Eingabe 1')\n",
        "plt.ylabel('Eingabe 2')\n",
        "plt.title('Entscheidungsgrenze als Linie (PyTorch)')\n",
        "plt.legend()\n",
        "plt.xlim(-0.1, 1.1)\n",
        "plt.ylim(-0.1, 1.1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDPJrd93sEr4"
      },
      "source": [
        "## Vergleich der Ergebnisse und Diskussion\n",
        "\n",
        "Vergleichen Sie die Ergebnisse beider Implementierungen:\n",
        "\n",
        "1. Sind die gelernten Gewichte und Bias ähnlich?\n",
        "2. Sind die Entscheidungsgrenzen ähnlich?\n",
        "3. Welche Vorteile bietet die PyTorch-Implementierung?\n",
        "4. Was ist der Unterschied im Code zwischen beiden Implementierungen?\n",
        "\n",
        "### Bonusaufgaben\n",
        "\n",
        "1. Implementieren Sie das Perzeptron für die XOR-Operation. Warum funktioniert das nicht? Was brauchen wir, um XOR zu lernen?\n",
        "2. Experimentieren Sie mit verschiedenen Lernraten. Wie wirkt sich das auf das Training aus?\n",
        "3. Implementieren Sie ein mehrschichtiges neuronales Netz (MLP) mit PyTorch, das die XOR-Operation lernen kann."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "vG8hpAzIsEr4",
        "outputId": "60e84af0-a76a-4655-c4e3-118394a4132c"
      },
      "outputs": [],
      "source": [
        "# Bonusaufgabe 1: XOR-Operation\n",
        "# Ausgabedaten für XOR-Operation\n",
        "y_xor = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "# Visualisieren der XOR-Daten\n",
        "visualize_data(X, y_xor)\n",
        "# Versuchen Sie, ein einfaches Perzeptron auf die XOR-Daten zu trainieren\n",
        "# und beobachten Sie die Ergebnisse!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
